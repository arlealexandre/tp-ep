---
title: "Scheduling disciplines for the G/G/k queue<br><small>Ã‰valuation de Performances 2024, DM, INFO4, Polytech Grenoble</small>"
author: "Alexandre Arle - MIRAS Romain"
date: "2024-03-17"
output: html_document
---

### A general code

The aim of this homework assignment is to be able to simulate and compare the dynamics of a G/G/k queue adopting a number of scheduling disciplines.
The following code provides a basis for implementing and testing other scheduling disciplines.


```{r eval=TRUE, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

# This function plot the average response time of a M/G/1 queue for various scheduling disciplines.
# As input, it takes the number of servers (k), their job service times (Service) with their mean value (ES)
plot_response_times <- function(k, Service, ES){
  
  debug=0;
  scheduling_disciplines = c(1:4); # 'FCFS'=1,'LCFS'=2,'RO-S'=3,'SRPT'=4
  num_arrival_rates=5;
  lambdas = (1/ES) * c(1:num_arrival_rates)/(num_arrival_rates+1) ; # arrival rates
  
  # Matrix of average response times for all disciplines and arrival rates
  R_time <- matrix(0, nrow = length(scheduling_disciplines), ncol = length(lambdas));
  rownames(R_time) <- c("FCFS","LCFS","RO-S","SRPT");
  colnames(R_time) <- paste("rho=", round(lambdas*ES, digits = 3), sep = "");
  
  cnt=0;
  for (lambda in lambdas)
  {
    cnt=cnt+1;
    # Let's assume a Poisson process coming in, otherwise change the next line
    Arrival= cumsum(rexp(n=N, rate = lambda)); # Arrival times
    
    for (scheduling_discipline in scheduling_disciplines)
    {
      t = 0; # simulation time
      Remaining = rep(N, x=NA);    # Remaining service times of each job
      Completion = rep(N, x=NA);   # Completion time of each job
      
      AvgJobs = 0;
      CurrentTask = rep(k, x=NA); # Current task of each servers
      NextArrival = 1;
      while (TRUE) {
        
        if (debug==1){
          print("*********************");
          print(paste("Scheduling discipline = ",scheduling_discipline));
          print(Arrival);
          print(Service);
          print(Remaining);
          
        }
        
        dtA = NA;
        dtC = rep(k, x=NA);
        if(length(Arrival[Arrival>t])>0) { # if an arrival exists after t
          dtA = head(Arrival[Arrival>t],n=1)-t ; # time to next arrival
        }
        
        for (i in 1:k) {
          if(!is.na(CurrentTask[i])) { # if a task is running
            dtC[i] = Remaining[CurrentTask[i]]; # time to next completion
          } 
        }
        
        if(is.na(dtA) & all(is.na(dtC))) {
          break; # no more arrivals and no more completions
        } 
        
        minDtc = pmin(dtC,na.rm=T); # minimum time to completion between all servers
        dt = min(dtA,minDtc,na.rm=T); # time to next event
        
        # update system variables
        t = t + dt;
        AvgJobs=AvgJobs+dt*sum(!is.na(Remaining));
        
        if (debug==1){
          print(paste("Sim. time:", t));
          print(paste("# of jobs arrived: ", NextArrival));
        }
        # Job arrival
        
        if((NextArrival <=N) & (Arrival[NextArrival] == t)) { 
          Remaining[NextArrival] = Service[NextArrival];
          NextArrival = NextArrival + 1;
        }
        
        
        
        # Job departure
        for (i in 1:k) {
          if(!is.na(CurrentTask[i])) {
            Remaining[CurrentTask[i]] = Remaining[CurrentTask[i]] - dt ;
            if(Remaining[CurrentTask[i]] <= 0) {
              # CurrentTask completed
              Completion[CurrentTask[i]] = t;
              Remaining[CurrentTask[i]] = NA;
              CurrentTask[i] = NA;
            }
          } 
        }
        
        # Scheduling discipline
        WaitingListWithCurrentTask=(1:NextArrival)[!is.na(Remaining)]; # jobs that are waiting or running
        WaitingList = WaitingListWithCurrentTask[!WaitingListWithCurrentTask %in% CurrentTask]; # jobs that are waiting
        
        if(length(WaitingList)>0) {
          
          # FCFS
          if (scheduling_discipline==1){
            for (i in 1:k) {
              if (is.na(CurrentTask[i])) {
                CurrentTask[i] = head(WaitingList,n=1);
                break;
              }
            }
            
          }
          
          # LCFS
          if (scheduling_discipline==2){
            # We implement the non-preemptive version of LCFS: jobs are never killed/resumed
            for (i in 1:k) {
              if(is.na(CurrentTask[i])) {
                # here, a task is not running, so we find a new job to serve
                CurrentTask[i] = tail(WaitingList,n=1);
                break;
              } 
            }
          }
          
          # ROS: Random Order of Service
          if (scheduling_discipline==3){
            for (i in 1:k) {
              if(is.na(CurrentTask[i])) {
                # here, a task is not running, so we find a new job to serve
                if (length(WaitingList)>1) {
                  CurrentTask[i] = sample(WaitingList,size=1);
                } else{
                  CurrentTask[i] = WaitingList;
                }
                break;
              } 
            }
          }
          
          # SRPT: Shortest Remaining Processing Time
          if (scheduling_discipline==4){
            for (i in 1:k) {
              if(is.na(CurrentTask[i])) {
                # here, a task is not running, so we find a new job to serve
                if (length(WaitingList)>1) {
                  CurrentTask[i] = WaitingList[which.min(Remaining[WaitingList])];
                } else{
                  CurrentTask[i] = WaitingList;
                }
                break;
              } 
            }
          }
          
        }
        
        if (debug==1){
          print(CurrentTask)
          readline(prompt="Press [enter] to proceed")
        }
        
      } # while
      
      ResponseTime = mean(Completion-Arrival); #average response time
      AvgJobs=AvgJobs/(tail(Completion,n=1)-Arrival[1]);
      
      # Simulation completed. Let's verify Little law: N=lambda*R
      r_names=rownames(R_time)
      cat(paste("Sim. ",r_names[scheduling_discipline],"(rho=",round(lambda*ES,digits = 2),") completed."));
      cat(paste(" Little law verification: ", round(AvgJobs,digits = 4), "=N=lambda*R=", round(lambda*ResponseTime,digits = 4),"\n"));
      
      R_time[scheduling_discipline,cnt]=ResponseTime;
      
    } # loop scheduling discipline
    
  } # loop lambda
  
  cat("\nResponse time matrix:\n")
  print(R_time)
  
  matplot(t(R_time), type = "l", xlab="Load (lambda*E[S])", ylab="Avg Response Time", xaxt = "n", lwd = 3);
  legend("topleft", legend = rownames(R_time), col=1:4, pch=1);
  axis(side=1,at=1:ncol(R_time),labels=round(lambdas*ES, digits=3));
  
  return(R_time);
} # end function

```

### Let's start slowly

We first simulate the dynamics induced by 10 arrivals with 3 servers in order to provide numerical evidence that our
code is correct. We obtain:

```{r eval=TRUE, include=TRUE}
knitr::opts_chunk$set(echo = FALSE)

set.seed(11); # Set seed for reproducibility
N = 10; # number of jobs to simulate;
k = 3; # number of servers
mu=1;
Service=rexp(N,rate=mu/k); # Service times, the rate here is mu * k
plot_response_times(k, Service, 1/mu);

```

The plot shows the average response time for the different scheduling disciplines for the G/G/3 queue with 10 jobs.
If we look at the number obtain by the little law verification we can see that the code is working correctly because we have that the number of jobs in the system is equal to the arrival rate times the average response time. This is a fundamental property of queueing systems that is called Little's Law.
So we do have provide numerical evidence that our code is correct

Now, the goal is to compare the G/G/k queue with a G/G/1 queue having one server that is k times
faster. For increasing values of the load (i.e., arrival rate divided by service rate) and k = 5, plot the
ratio between the average response time obtained by a G/G/k/FCFS queue and the average response
time obtained by a G/G/1/FCFS queue with a server that operates at speed k.

```{r eval=TRUE, include=TRUE}
knitr::opts_chunk$set(echo = FALSE)

set.seed(11); # Set seed for reproducibility
N = 10; # number of jobs to simulate;
k=5
Service=rexp(N,rate=mu/k); # Service times, the rate here is mu * k

response_timesGGk = plot_response_times(1, Service, 1/mu);

response_timesGG1 = plot_response_times(1, Service, 1/mu*k);

```

The 2 different plot shows the average response time for the different scheduling disciplines for the G/G/k/FCFS queue and the G/G/1/FCFS queue with a server that operates at speed k. We can see that the average response time for the G/G/k/FCFS queue is always higher than the average response time for the G/G/1/FCFS queue with a server that operates at speed k. This is due to the fact that we have not enough jobs to keep all the servers busy in the G/G/k/FCFS queue. So the G/G/1 queue with a server that operates at speed k is always faster than the G/G/k queue for the considered load.

Now, let's plot the ratio between the average response time obtained by a G/G/k/FCFS queue and the average response time obtained by a G/G/1/FCFS queue with a server that operates at speed k.

```{r eval=TRUE, include=TRUE}
# plot the ratio between the average response time obtained by a G/G/k/FCFS queue and the average response time obtained by a G/G/1/FCFS queue with a server that operates at speed k

# By the first line of the matrix we can see the average response time for the different scheduling disciplines for the G/G/k/FCFS queue
ratio = response_timesGGk[1,]/response_timesGG1[1,]

plot(ratio, type = "l", xlab="Load (lambda*E[S])", ylab="Ratio between G/G/k/FCFS and G/G/1/FCFS", lwd = 3);

```

The plot shows the ratio between the average response time obtained by a G/G/k/FCFS queue and the average response time obtained by a G/G/1/FCFS queue with a server that operates at speed k. We can see that the ratio is always higher than 1 as we expected by the same reasoning we explained before.

### References

[1] Schrage, Linus. "A Proof of the Optimality of the Shortest Remaining Processing Time Discipline." Operations Research, vol. 16, no. 3, 1968, pp. 687â€“90.


<br><br>
