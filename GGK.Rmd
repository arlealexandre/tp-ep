---
title: "Scheduling disciplines for the G/G/k queue<br><small>Évaluation de Performances 2024, DM, INFO4, Polytech Grenoble</small>"
author: "Alexandre Arle"
date: "2024-03-17"
output: html_document
---

### A general code

The aim of this homework assignment is to be able to simulate and compare the dynamics of a G/G/k queue adopting a number of scheduling disciplines.
The following code provides a basis for implementing and testing other scheduling disciplines.


```{r eval=TRUE, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

# This function plot the average response time of a M/G/1 queue for various scheduling disciplines.
# As input, it takes the number of servers (k), their job service times (Service) with their mean value (ES)
plot_response_times <- function(k, Service, ES){

    debug=0;
    scheduling_disciplines = c(1:4); # 'FCFS'=1,'LCFS'=2,'RO-S'=3,'SRPT'=4
    num_arrival_rates=5;
    lambdas = (1/ES) * c(1:num_arrival_rates)/(num_arrival_rates+1) ;
    
    # Matrix of average response times for all disciplines and arrival rates
    R_time <- matrix(0, nrow = length(scheduling_disciplines), ncol = length(lambdas));
    rownames(R_time) <- c("FCFS","LCFS","RO-S","SRPT");
    colnames(R_time) <- paste("rho=", round(lambdas*ES, digits = 3), sep = "");
    
    cnt=0;
    for (lambda in lambdas)
    {
      cnt=cnt+1;
      # Let's assume a Poisson process coming in, otherwise change the next line
      Arrival= cumsum(rexp(n=N, rate = lambda)); # Arrival times
  
      for (scheduling_discipline in scheduling_disciplines)
      {
        t = 0; # simulation time
        Remaining = rep(N, x=NA);    # Remaining service times of each job
        Completion = rep(N, x=NA);   # Completion time of each job
        
        AvgJobs = 0;
        CurrentTask = rep(k, x=NA); # Current task of each servers
        NextArrival = 1;
        while (TRUE) {
        
        if (debug==1){
            print("*********************");
            print(paste("Scheduling discipline = ",scheduling_discipline));
            print(Arrival);
            print(Service);
            print(Remaining);
          
        }
      
            dtA = NA;
            dtC = rep(k, x=NA);
            if(length(Arrival[Arrival>t])>0) { # if an arrival exists after t
                dtA = head(Arrival[Arrival>t],n=1)-t ; # time to next arrival
            }
            
            for (i in 1:k) {
              if(!is.na(CurrentTask[i])) { # if a task is running
                dtC[i] = Remaining[CurrentTask[i]]; # time to next completion
              } 
            }
            
            if(is.na(dtA) & all(is.na(dtC))) {
                break;
            } 
        
            minDtc = pmin(dtC,na.rm=T);
            dt = min(dtA,minDtc,na.rm=T);
        
            # update system variables
            t = t + dt;
            AvgJobs=AvgJobs+dt*sum(!is.na(Remaining));
      
        if (debug==1){
            print(paste("Sim. time:", t));
            print(paste("# of jobs arrived: ", NextArrival));
        }
            # Job arrival
            
            if((NextArrival <=N) & (Arrival[NextArrival] == t)) {
                Remaining[NextArrival] = Service[NextArrival];
                NextArrival = NextArrival + 1;
            }
            
            
      
            # Job departure
            for (i in 1:k) {
              if(!is.na(CurrentTask[i])) {
                  Remaining[CurrentTask[i]] = Remaining[CurrentTask[i]] - dt ;
                  if(Remaining[CurrentTask[i]] <= 0) {
                      # CurrentTask completed
                      Completion[CurrentTask[i]] = t;
                      Remaining[CurrentTask[i]] = NA;
                      CurrentTask[i] = NA;
                  }
              } 
            }
            
            # Scheduling discipline
            # but substract all current tas
            WaitingListWithCurrentTask=(1:NextArrival)[!is.na(Remaining)];
            WaitingList = WaitingListWithCurrentTask[!WaitingListWithCurrentTask %in% CurrentTask];
            #print(WaitingList)
           
            if(length(WaitingList)>0) {
      
              # FCFS
              if (scheduling_discipline==1){
                
                for (i in 1:k) {
                  if (is.na(CurrentTask[i])) {
                    CurrentTask[i] = head(WaitingList,n=1);
                    break;
                  }
                }
                
              }
              
              # LCFS
              if (scheduling_discipline==2){
                # We implement the non-preemptive version of LCFS: jobs are never killed/resumed
                for (i in 1:k) {
                  if(is.na(CurrentTask[i])) {
                  # here, a task is not running, so we find a new job to serve
                    CurrentTask[i] = tail(WaitingList,n=1);
                    break;
                  } 
                }
              }
              
              # ROS: Random Order of Service
              if (scheduling_discipline==3){
                for (i in 1:k) {
                  if(is.na(CurrentTask[i])) {
                  # here, a task is not running, so we find a new job to serve
                    if (length(WaitingList)>1) {
                      CurrentTask[i] = sample(WaitingList,size=1);
                    } else{
                      CurrentTask[i] = WaitingList;
                    }
                    break;
                  } 
                }
              }
              
              # SRPT: Shortest Remaining Processing Time
              if (scheduling_discipline==4){
                for (i in 1:k) {
                  if (!is.na(CurrentTask[i])) {
                    CurrentTask[i] = which.min(Remaining);   
                  }
                }
              }
      
            }
            
        if (debug==1){
            print(CurrentTask)
            readline(prompt="Press [enter] to proceed")
        }
            
        } # while
        
        ResponseTime = mean(Completion-Arrival); #average response time
        AvgJobs=AvgJobs/(tail(Completion,n=1)-Arrival[1]);
  
        # Simulation completed. Let's verify Little law: N=lambda*R
        r_names=rownames(R_time)
        cat(paste("Sim. ",r_names[scheduling_discipline],"(rho=",round(lambda*ES,digits = 2),") completed."));
        cat(paste(" Little law verification: ", round(AvgJobs,digits = 4), "=N=lambda*R=", round(lambda*ResponseTime,digits = 4),"\n"));
        
        R_time[scheduling_discipline,cnt]=ResponseTime;
  
      } # loop scheduling discipline
    
    } # loop lambda
    
    cat("\nResponse time matrix:\n")
    print(R_time)
    
    matplot(t(R_time), type = "l", xlab="Load (lambda*E[S])", ylab="Avg Response Time", xaxt = "n", lwd = 3);
    legend("topleft", legend = rownames(R_time), col=1:4, pch=1);
    axis(side=1,at=1:ncol(R_time),labels=round(lambdas*ES, digits=3));


} # end function

```

### Let's start slowly

We first simulate the dynamics induced by 10 arrivals with 3 servers in order to provide numerical evidence that our
code is correct. We obtain:

```{r eval=TRUE, include=TRUE}
knitr::opts_chunk$set(echo = FALSE)

set.seed(11); # Set seed for reproducibility
N = 1e4; # number of jobs to simulate;
k = 10; # number of servers
mu=1;
Service=rexp(N,rate=mu/k); # Service times, the rate here is mu * k
plot_response_times(k, Service, 1/mu);

```

Then, let us assume that service times follows a Pareto$(x_m,\alpha)$ distribution where $x_m$ and $\alpha$ are the scale and shape parameters, respectively. Let us assume $\alpha=3$ and $x_m=1$. We obtain:

```{r eval=TRUE, include=TRUE}
knitr::opts_chunk$set(echo = FALSE)

xm=1; alpha=3;
set.seed(11); # Set seed for reproducibility
N = 5e3; # number of jobs to simulate;
k=2
Service=xm/(runif(N)^(1/alpha)); # This generates Pareto samples

plot_response_times(k,Service, xm*alpha/(alpha-1));

```

From the plots, we see that FCFS, LCFS and ROS provide the same average response time. SRPT seems to be the best, and this is indeed the case in a broad sense [1].  However, SRPT remains a bit ideal because one does not really know how much processing time remains for any given job. To patch this, a possibility would be to consider SERPT, i.e., Shortest Expected Remaining Processing Time, which has an obvious meaning; this policy may make sense in practice because the service time distribution is known, as it can be learned from the data. Or, would it be possible to do even better than SERPT?


### References

[1] Schrage, Linus. "A Proof of the Optimality of the Shortest Remaining Processing Time Discipline." Operations Research, vol. 16, no. 3, 1968, pp. 687–90.


<br><br>
